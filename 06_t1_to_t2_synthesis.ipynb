{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 06_t1_to_t2_synthesis.ipynb — T1→T2 generation\n\n",
    "Goal:\n",
    "- Load paired T1/T2 PNGs (256×256, grayscale).\n",
    "- Use a conditional generator (Pix2Pix U-Net) to synthesize T2 from T1.\n",
    "- Evaluate with SSIM/PSNR and save example grids.\n",
    "- Includes Colab-friendly setup and automatic fallbacks to sample data.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Colab setup: clone repo, install deps, and create sample data\n",
    "import os, sys, subprocess\n",
    "from pathlib import Path\n",
    "\n",
    "IN_COLAB = False\n",
    "try:\n",
    "    import google.colab  # type: ignore\n",
    "    IN_COLAB = True\n",
    "except Exception:\n",
    "    pass\n",
    "\n",
    "repo_url = \"https://github.com/julietam/GenerativeAI_Medical_Images.git\"\n",
    "workdir = Path(\"/content/GenerativeAI_Medical_Images\") if IN_COLAB else Path.cwd()\n",
    "\n",
    "if IN_COLAB:\n",
    "    if not workdir.exists():\n",
    "        subprocess.run([\"git\", \"clone\", repo_url, str(workdir)], check=True)\n",
    "    else:\n",
    "        subprocess.run([\"git\", \"-C\", str(workdir), \"pull\", \"--ff-only\"], check=False)\n",
    "    os.chdir(workdir)\n",
    "\n",
    "subprocess.run([sys.executable, \"-m\", \"pip\", \"install\", \"-q\", \"-r\", \"requirements.txt\"], check=False)\n",
    "subprocess.run([sys.executable, \"-m\", \"pip\", \"install\", \"-q\", \"torchmetrics\", \"monai\", \"pandas\"], check=False)\n",
    "subprocess.run([sys.executable, \"scripts/make_sample_data.py\"], check=False)\n",
    "print(\"Setup done. CWD =\", Path.cwd())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data paths: prefer real pairs in data/paired_mri; fallback to data/sample_mri_pairs\n",
    "from pathlib import Path\n",
    "import subprocess, sys\n",
    "paired_root = Path('data/paired_mri')\n",
    "sample_root = Path('data/sample_mri_pairs')\n",
    "t1_dir = paired_root/'T1'; t2_dir = paired_root/'T2'\n",
    "if not any(t1_dir.glob('*.png')) or not any(t2_dir.glob('*.png')):\n",
    "    # try to ensure samples exist\n",
    "    try:\n",
    "        subprocess.run([sys.executable, 'scripts/make_sample_data.py'], check=False)\n",
    "    except Exception as e:\n",
    "        print('Warning: could not generate sample data:', e)\n",
    "    if any((sample_root/'T1').glob('*.png')) and any((sample_root/'T2').glob('*.png')):\n",
    "        paired_root = sample_root\n",
    "        t1_dir = sample_root/'T1'; t2_dir = sample_root/'T2'\n",
    "print('Using pairs from', paired_root)\n",
    "n_t1 = len(list(t1_dir.glob('*.png'))); n_t2 = len(list(t2_dir.glob('*.png')))\n",
    "print('Found', n_t1, 'T1 and', n_t2, 'T2')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dataset and transforms (grayscale → [-1,1])\n",
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torchvision import transforms\n",
    "from PIL import Image\n",
    "\n",
    "img_size = 256\n",
    "tf = transforms.Compose([\n",
    "    transforms.Grayscale(num_output_channels=1),\n",
    "    transforms.Resize((img_size, img_size)),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize([0.5],[0.5]),\n",
    "])\n",
    "\n",
    "class PairedMRIDataset(Dataset):\n",
    "    def __init__(self, root):\n",
    "        root = Path(root)\n",
    "        self.a = sorted((root/'T1').glob('*.png'))\n",
    "        self.b = sorted((root/'T2').glob('*.png'))\n",
    "        assert len(self.a) == len(self.b) and len(self.a) > 0, 'Need paired PNGs under T1/ and T2/'\n",
    "    def __len__(self): return len(self.a)\n",
    "    def __getitem__(self, i):\n",
    "        A = tf(Image.open(self.a[i]).convert('L'))\n",
    "        B = tf(Image.open(self.b[i]).convert('L'))\n",
    "        return A, B\n",
    "\n",
    "ds = PairedMRIDataset(paired_root)\n",
    "dl = DataLoader(ds, batch_size=4, shuffle=False, num_workers=2)\n",
    "print('Dataset size =', len(ds))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model: Pix2Pix U-Net generator; load checkpoint if available or do a brief fine-tune\n",
    "from src.models.pix2pix import UNetGenerator, PatchGANDiscriminator\n",
    "from torch import nn, optim\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "G = UNetGenerator(in_channels=1, out_channels=1).to(device)\n",
    "ckpt_candidates = [\n",
    "    Path('outputs/pix2pix/best.pt'),\n",
    "    Path('outputs/pix2pix/last.pt'),\n",
    "]\n",
    "loaded=False\n",
    "for c in ckpt_candidates:\n",
    "    if c.exists():\n",
    "        try:\n",
    "            G.load_state_dict(torch.load(c, map_location=device))\n",
    "            print('Loaded checkpoint:', c)\n",
    "            loaded=True; break\n",
    "        except Exception as e:\n",
    "            print('Failed to load', c, e)\n",
    "\n",
    "if not loaded:\n",
    "    print('No checkpoint found. Running a very brief fine-tune (few iterations) to warm-start...')\n",
    "    D = PatchGANDiscriminator(in_channels=2).to(device)\n",
    "    opt_g = optim.Adam(G.parameters(), lr=2e-4, betas=(0.5,0.999))\n",
    "    opt_d = optim.Adam(D.parameters(), lr=2e-4, betas=(0.5,0.999))\n",
    "    L1 = nn.L1Loss(); BCE = nn.BCEWithLogitsLoss()\n",
    "    G.train(); D.train()\n",
    "    steps=0\n",
    "    for A,B in dl:\n",
    "        A,B = A.to(device), B.to(device)\n",
    "        # D\n",
    "        opt_d.zero_grad()\n",
    "        Z = G(A)\n",
    "        pred_real = D(A,B)\n",
    "        pred_fake = D(A,Z.detach())\n",
    "        loss_d = BCE(pred_real, torch.ones_like(pred_real)) + BCE(pred_fake, torch.zeros_like(pred_fake))\n",
    "        loss_d.backward(); opt_d.step()\n",
    "        # G\n",
    "        opt_g.zero_grad()\n",
    "        pred_fake = D(A,Z)\n",
    "        loss_g = BCE(pred_fake, torch.ones_like(pred_fake)) + 100*L1(Z,B)\n",
    "        loss_g.backward(); opt_g.step()\n",
    "        steps += 1\n",
    "        if steps >= 50: break\n",
    "    G.eval()\n",
    "else:\n",
    "    G.eval()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate both models and build a metrics table\n",
    "import os\n",
    "import pandas as pd\n",
    "from src.utils.visualization import show_images\n",
    "from torchmetrics.image import StructuralSimilarityIndexMeasure, PeakSignalNoiseRatio\n",
    "\n",
    "os.makedirs('outputs/t1_to_t2', exist_ok=True)\n",
    "\n",
    "def evaluate(forward):\n",
    "    ssim_metric = StructuralSimilarityIndexMeasure(data_range=1.0).to(device)\n",
    "    psnr_metric = PeakSignalNoiseRatio(data_range=1.0).to(device)\n",
    "    ssims, psnrs = [], []\n",
    "    first = True\n",
    "    cache = None\n",
    "    with torch.no_grad():\n",
    "        for i, (A,B) in enumerate(dl):\n",
    "            A,B = A.to(device), B.to(device)\n",
    "            Z = forward(A)\n",
    "            Z01, B01 = (Z+1)/2, (B+1)/2\n",
    "            ssims.append(ssim_metric(Z01, B01).item())\n",
    "            psnrs.append(psnr_metric(Z01, B01).item())\n",
    "            if first:\n",
    "                cache = (A[:4].cpu(), Z[:4].cpu(), B[:4].cpu())\n",
    "                first = False\n",
    "    val_ssim = float(sum(ssims)/len(ssims)) if ssims else 0.0\n",
    "    val_psnr = float(sum(psnrs)/len(psnrs)) if psnrs else 0.0\n",
    "    return val_ssim, val_psnr, cache\n",
    "\n",
    "# Pix2Pix\n",
    "ssim_g, psnr_g, cache_g = evaluate(lambda x: G(x))\n",
    "if cache_g is not None:\n",
    "    a,z,b = cache_g\n",
    "    show_images(torch.cat([a, z, b], dim=0), nrow=4, title='Pix2Pix: A, G(A), B', save_path='outputs/t1_to_t2/grid_pix2pix.png')\n",
    "\n",
    "# MONAI UNet\n",
    "ssim_m, psnr_m, cache_m = evaluate(lambda x: M(x))\n",
    "if cache_m is not None:\n",
    "    a2,z2,b2 = cache_m\n",
    "    show_images(torch.cat([a2, z2, b2], dim=0), nrow=4, title='MONAI UNet: A, M(A), B', save_path='outputs/t1_to_t2/grid_monai_unet.png')\n",
    "\n",
    "# Table\n",
    "results = [\n",
    "    {'model': 'Pix2Pix-UNet', 'SSIM': ssim_g, 'PSNR': psnr_g},\n",
    "    {'model': 'MONAI-UNet (L1)', 'SSIM': ssim_m, 'PSNR': psnr_m},\n",
    "]\n",
    "df = pd.DataFrame(results)\n",
    "print(df)\n",
    "df.to_csv('outputs/t1_to_t2/metrics.csv', index=False)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
