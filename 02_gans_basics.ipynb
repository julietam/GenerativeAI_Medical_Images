{
 "cells": [
  {"cell_type": "markdown", "metadata": {}, "source": ["# 02_gans_basics.ipynb — DCGAN desde cero\n\nEste notebook muestra un entrenamiento básico de DCGAN para imágenes médicas (p.ej., 64x64 o 128x128, 1 canal).\n"]},
  {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["import sys, os\nif '.' not in sys.path: sys.path.append('.')\nimport torch\nfrom torch import nn, optim\nfrom torch.utils.data import DataLoader\nfrom torchvision import datasets, transforms, utils\nfrom src.models.dcgan import DCGANGenerator, DCGANDiscriminator\nfrom src.utils.visualization import show_images\n"]},
  {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\nimg_size = 64\nbatch_size = 64\nz_dim = 100\nchannels = 1\ntransform = transforms.Compose([\n    transforms.Grayscale(num_output_channels=1),\n    transforms.Resize((img_size, img_size)),\n    transforms.ToTensor(),\n    transforms.Normalize([0.5], [0.5]),\n])\n# TODO: Reemplaza por tu dataset de imágenes médicas\ndataset = datasets.FakeData(size=1024, image_size=(1, img_size, img_size), transform=transforms.Compose([transforms.ToTensor(), transforms.Normalize([0.5],[0.5])]))\nloader = DataLoader(dataset, batch_size=batch_size, shuffle=True, num_workers=2)\n\nG = DCGANGenerator(z_dim=z_dim, img_channels=channels, img_size=img_size).to(device)\nD = DCGANDiscriminator(img_channels=channels, img_size=img_size).to(device)\nopt_g = optim.Adam(G.parameters(), lr=2e-4, betas=(0.5, 0.999))\nopt_d = optim.Adam(D.parameters(), lr=2e-4, betas=(0.5, 0.999))\ncriterion = nn.BCEWithLogitsLoss()\n"]},
  {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["epochs = 1  # sube a 50+ para resultados reales\nfor epoch in range(epochs):\n    for i, (x, _) in enumerate(loader):\n        x = (x - 0.5) / 0.5\n        x = x.to(device)\n        b = x.size(0)\n        z = torch.randn(b, z_dim, device=device)\n        # ---- Train D ----\n        opt_d.zero_grad()\n        real_logits = D(x)\n        fake_imgs = G(z)\n        fake_logits = D(fake_imgs.detach())\n        loss_d = criterion(real_logits, torch.ones_like(real_logits)) + \\
                 criterion(fake_logits, torch.zeros_like(fake_logits))\n        loss_d.backward()\n        opt_d.step()\n        # ---- Train G ----\n        opt_g.zero_grad()\n        fake_logits = D(fake_imgs)\n        loss_g = criterion(fake_logits, torch.ones_like(fake_logits))\n        loss_g.backward()\n        opt_g.step()\n        if i % 100 == 0:\n            print(f'Epoch {epoch} Iter {i}: D {loss_d.item():.3f} | G {loss_g.item():.3f}')\n    with torch.no_grad():\n        samples = G(torch.randn(32, z_dim, device=device))\n        show_images(samples.cpu(), nrow=8, title=f'Epoch {epoch}')\n"]},
  {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": [
   "from src.utils.metrics import fid, inception_score\n",
   "from src.utils.visualization import plot_curves\n",
   "from torchvision import models, transforms as T\n",
   "import torch, os\n",
   "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
   "G.eval()\n",
   "# validation set (proxy)\n",
   "full_ds = datasets.FakeData(size=256, image_size=(1, img_size, img_size), transform=transforms.Compose([transforms.ToTensor(), transforms.Normalize([0.5],[0.5])]))\n",
   "from torch.utils.data import DataLoader\n",
   "val_dl = DataLoader(full_ds, batch_size=batch_size, shuffle=False, num_workers=2)\n",
   "# feature extractor (ResNet18) for FID/IS proxies\n",
   "try:\n",
   "    resnet = models.resnet18(weights=models.ResNet18_Weights.DEFAULT).eval().to(device)\n",
   "    feat = torch.nn.Sequential(*(list(resnet.children())[:-1]))\n",
   "except Exception as e:\n",
   "    print('Warning: could not load pretrained weights:', e)\n",
   "    resnet = models.resnet18(weights=None).eval().to(device)\n",
   "    feat = torch.nn.Sequential(*(list(resnet.children())[:-1]))\n",
   "prep = T.Compose([T.Resize((224,224)), T.Lambda(lambda t: t.repeat(1,3,1,1) if t.size(1)==1 else t)])\n",
   "def get_feats_and_logits(x):\n",
   "    x = (x+1)/2 if x.min()<0 else x\n",
   "    x = prep(x)\n",
   "    with torch.no_grad():\n",
   "        f = feat(x).flatten(1)\n",
   "        logits = resnet(x)\n",
   "    return f, logits\n",
   "# collect real feats\n",
   "real_feats = []\n",
   "for xr,_ in val_dl:\n",
   "    xr = xr.to(device)\n",
   "    f,_ = get_feats_and_logits(xr)\n",
   "    real_feats.append(f)\n",
   "real_feats = torch.cat(real_feats, dim=0)\n",
   "# generate fake and collect feats/logits\n",
   "fake_feats = []\n",
   "all_logits = []\n",
   "with torch.no_grad():\n",
   "    need = real_feats.size(0)\n",
   "    out = []\n",
   "    while sum(t.size(0) for t in out) < need:\n",
   "        z = torch.randn(batch_size, z_dim, device=device)\n",
   "        g = G(z)\n",
   "        out.append(g)\n",
   "    fake = torch.cat(out, dim=0)[:need]\n",
   "    for i in range(0, need, batch_size):\n",
   "        f, logits = get_feats_and_logits(fake[i:i+batch_size])\n",
   "        fake_feats.append(f)\n",
   "        all_logits.append(logits)\n",
   "fake_feats = torch.cat(fake_feats, dim=0)\n",
   "all_logits = torch.cat(all_logits, dim=0)\n",
   "fid_val = fid(real_feats, fake_feats)\n",
   "is_mean, is_std = inception_score(all_logits, splits=1)\n",
   "print({'FID_proxy': fid_val, 'IS_proxy_mean': is_mean, 'IS_proxy_std': is_std})\n",
   "history = {'FID_proxy':[fid_val], 'IS_proxy_mean':[is_mean]}\n",
   "os.makedirs('outputs/dcgan', exist_ok=True)\n",
   "plot_curves(history, title='DCGAN validation (FID/IS proxies)')\n"
  ]}
 ],
 "metadata": {
  "kernelspec": {"display_name": "Python 3", "language": "python", "name": "python3"},
  "language_info": {"name": "python", "version": "3.10"}
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
