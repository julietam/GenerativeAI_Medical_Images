{
 "cells": [
  {"cell_type": "markdown", "metadata": {}, "source": ["# 02_gans_basics.ipynb — DCGAN desde cero\n\nEste notebook muestra un entrenamiento básico de DCGAN para imágenes médicas (p.ej., 64x64 o 128x128, 1 canal).\n"]},
  {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["import sys, os\nif '.' not in sys.path: sys.path.append('.')\nimport torch\nfrom torch import nn, optim\nfrom torch.utils.data import DataLoader\nfrom torchvision import datasets, transforms, utils\nfrom src.models.dcgan import DCGANGenerator, DCGANDiscriminator\nfrom src.utils.visualization import show_images\n"]},
  {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\nimg_size = 64\nbatch_size = 64\nz_dim = 100\nchannels = 1\ntransform = transforms.Compose([\n    transforms.Grayscale(num_output_channels=1),\n    transforms.Resize((img_size, img_size)),\n    transforms.ToTensor(),\n    transforms.Normalize([0.5], [0.5]),\n])\n# Usa datos reales si existen en data/paired_mri/T1; si no, intenta samples; finalmente FakeData\nfrom pathlib import Path\nfrom PIL import Image\nfrom torch.utils.data import Dataset\nclass PNGFolderDataset(Dataset):\n    def __init__(self, root, transform):\n        self.paths = sorted(Path(root).glob('*.png'))\n        self.tf = transform\n    def __len__(self): return len(self.paths)\n    def __getitem__(self, i):\n        img = Image.open(self.paths[i]).convert('L')\n        return self.tf(img), 0\nroot_t1 = Path('data/paired_mri')/'T1'\nsample_t1 = Path('data/sample_mri_pairs')/'T1'\nif any(root_t1.glob('*.png')):\n    dataset = PNGFolderDataset(root_t1, transform)\nelif any(sample_t1.glob('*.png')):\n    dataset = PNGFolderDataset(sample_t1, transform)\nelse:\n    # último recurso\n    dataset = datasets.FakeData(size=1024, image_size=(1, img_size, img_size), transform=transforms.Compose([transforms.ToTensor(), transforms.Normalize([0.5],[0.5])]))\nloader = DataLoader(dataset, batch_size=batch_size, shuffle=True, num_workers=2)\n\nG = DCGANGenerator(z_dim=z_dim, img_channels=channels, img_size=img_size).to(device)\nD = DCGANDiscriminator(img_channels=channels, img_size=img_size).to(device)\nopt_g = optim.Adam(G.parameters(), lr=2e-4, betas=(0.5, 0.999))\nopt_d = optim.Adam(D.parameters(), lr=2e-4, betas=(0.5, 0.999))\ncriterion = nn.BCEWithLogitsLoss()\n"]},
  {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["epochs = 1  # sube a 50+ para resultados reales\nfor epoch in range(epochs):\n    for i, (x, _) in enumerate(loader):\n        x = (x - 0.5) / 0.5\n        x = x.to(device)\n        b = x.size(0)\n        z = torch.randn(b, z_dim, device=device)\n        # ---- Train D ----\n        opt_d.zero_grad()\n        real_logits = D(x)\n        fake_imgs = G(z)\n        fake_logits = D(fake_imgs.detach())\n        loss_d = criterion(real_logits, torch.ones_like(real_logits)) + \\
                 criterion(fake_logits, torch.zeros_like(fake_logits))\n        loss_d.backward()\n        opt_d.step()\n        # ---- Train G ----\n        opt_g.zero_grad()\n        fake_logits = D(fake_imgs)\n        loss_g = criterion(fake_logits, torch.ones_like(fake_logits))\n        loss_g.backward()\n        opt_g.step()\n        if i % 100 == 0:\n            print(f'Epoch {epoch} Iter {i}: D {loss_d.item():.3f} | G {loss_g.item():.3f}')\n    with torch.no_grad():\n        samples = G(torch.randn(32, z_dim, device=device))\n        show_images(samples.cpu(), nrow=8, title=f'Epoch {epoch}')\n"]},
  {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": [
   "from torchmetrics.image.fid import FrechetInceptionDistance\n",
   "from torchmetrics.image.inception import InceptionScore\n",
   "from src.utils.visualization import plot_curves, show_images\n",
   "import torch, os\n",
   "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
   "G.eval()\n",
   "# validation set\n",
   "full_ds = datasets.FakeData(size=256, image_size=(1, img_size, img_size), transform=transforms.Compose([transforms.ToTensor(), transforms.Normalize([0.5],[0.5])]))\n",
   "from torch.utils.data import DataLoader\n",
   "val_dl = DataLoader(full_ds, batch_size=batch_size, shuffle=False, num_workers=2)\n",
   "fid = FrechetInceptionDistance(normalize=True).to(device)\n",
   "is_metric = InceptionScore(splits=1, normalize=True).to(device)\n",
   "# real updates\n",
   "for xr,_ in val_dl:\n",
   "    xr = xr.to(device)\n",
   "    xr01 = (xr + 1)/2\n",
   "    fid.update(xr01, real=True)\n",
   "# fake updates (match count)\n",
   "need = len(full_ds)\n",
   "gen = []\n",
   "with torch.no_grad():\n",
   "    while sum(t.size(0) for t in gen) < need:\n",
   "        z = torch.randn(batch_size, z_dim, device=device)\n",
   "        g = G(z)\n",
   "        gen.append(g)\n",
   "fake = torch.cat(gen, dim=0)[:need]\n",
   "fake01 = (fake + 1)/2\n",
   "for i in range(0, fake01.size(0), batch_size):\n",
   "    fbatch = fake01[i:i+batch_size]\n",
   "    fid.update(fbatch, real=False)\n",
   "    is_metric.update(fbatch)
",
   "fid_val = float(fid.compute())\n",
   "is_mean, is_std = is_metric.compute()\n",
   "is_mean, is_std = float(is_mean), float(is_std)\n",
   "print({'FID': fid_val, 'IS_mean': is_mean, 'IS_std': is_std})\n",
   "os.makedirs('outputs/dcgan', exist_ok=True)\n",
   "plot_curves({'FID':[fid_val], 'IS_mean':[is_mean]}, title='DCGAN validation (TorchMetrics)', save_path='outputs/dcgan/metrics.png')\n",
   "show_images(fake[:32].cpu(), nrow=8, title='DCGAN samples (val)', save_path='outputs/dcgan/samples.png')\n"
  ]}
 ],
 "metadata": {
  "kernelspec": {"display_name": "Python 3", "language": "python", "name": "python3"},
  "language_info": {"name": "python", "version": "3.10"}
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
