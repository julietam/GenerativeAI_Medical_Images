# GeneraciÃ³n y ValidaciÃ³n de ImÃ¡genes MÃ©dicas: Retos, Riesgos y Oportunidades

[![License: MIT](https://img.shields.io/badge/License-MIT-yellow.svg)](https://opensource.org/licenses/MIT)
[![Python 3.8+](https://img.shields.io/badge/python-3.8+-blue.svg)](https://www.python.org/downloads/)
[![PyTorch](https://img.shields.io/badge/PyTorch-2.0+-red.svg)](https://pytorch.org/)

> Repositorio educativo para la plÃ¡tica sobre modelos generativos en imagenologÃ­a mÃ©dica  
> **Audiencia**: Estudiantes de MaestrÃ­a en Ciencias e IngenierÃ­a de la ComputaciÃ³n

---

## ğŸ“‹ Contenido del Repositorio

```
medical-image-generation/
â”œâ”€â”€ README.md                          # Este archivo
â”œâ”€â”€ slides/                            # PresentaciÃ³n
â”‚   â”œâ”€â”€ slides.pdf
â”‚   â””â”€â”€ figures/
â”œâ”€â”€ notebooks/                         # Jupyter notebooks
â”‚   â”œâ”€â”€ 01_introduction.ipynb         # Explorando datasets mÃ©dicos
â”‚   â”œâ”€â”€ 02_gans_basics.ipynb          # GANs desde cero
â”‚   â”œâ”€â”€ 03_pix2pix_mri.ipynb         # MRI T1â†’T2 con Pix2Pix
â”‚   â”œâ”€â”€ 04_cyclegan_ct_mri.ipynb     # MRIâ†”CT con CycleGAN
â”‚   â”œâ”€â”€ 05_diffusion_xray.ipynb      # Chest X-ray con Diffusion
â”‚   â””â”€â”€ 06_medigan_demo.ipynb        # Demo con modelos pre-entrenados
â”œâ”€â”€ src/                               # CÃ³digo fuente
â”‚   â”œâ”€â”€ models/
â”‚   â”‚   â”œâ”€â”€ dcgan.py
â”‚   â”‚   â”œâ”€â”€ pix2pix.py
â”‚   â”‚   â”œâ”€â”€ cyclegan.py
â”‚   â”‚   â””â”€â”€ diffusion.py
â”‚   â”œâ”€â”€ data/
â”‚   â”‚   â”œâ”€â”€ datasets.py
â”‚   â”‚   â””â”€â”€ preprocessing.py
â”‚   â”œâ”€â”€ utils/
â”‚   â”‚   â”œâ”€â”€ metrics.py                # FID, IS, SSIM, PSNR
â”‚   â”‚   â”œâ”€â”€ visualization.py
â”‚   â”‚   â””â”€â”€ medical_utils.py          # DICOM, NIfTI handling
â”‚   â””â”€â”€ train.py
â”œâ”€â”€ data/                              # Datasets (gitignore, solo scripts)
â”‚   â”œâ”€â”€ download_datasets.sh
â”‚   â””â”€â”€ README.md                      # Instrucciones de descarga
â”œâ”€â”€ results/                           # Resultados generados
â”‚   â””â”€â”€ .gitkeep
â”œâ”€â”€ docs/                              # DocumentaciÃ³n adicional
â”‚   â”œâ”€â”€ PLAN_PLATICA.md               # Plan completo de la plÃ¡tica
â”‚   â”œâ”€â”€ REFERENCIAS.md                # Papers y recursos
â”‚   â””â”€â”€ SETUP.md                      # GuÃ­a de instalaciÃ³n detallada
â”œâ”€â”€ requirements.txt                   # Dependencias Python
â”œâ”€â”€ environment.yml                    # Conda environment
â””â”€â”€ LICENSE

```

---

## ğŸš€ Inicio RÃ¡pido

### 1. Clonar el Repositorio

```bash
git clone https://github.com/tu-usuario/medical-image-generation.git
cd medical-image-generation
```

### 2. Configurar Entorno

#### OpciÃ³n A: Conda (Recomendado)

```bash
conda env create -f environment.yml
conda activate medgen
```

#### OpciÃ³n B: pip + virtualenv

```bash
python -m venv venv
source venv/bin/activate  # En Windows: venv\Scripts\activate
pip install -r requirements.txt
```

### 3. Descargar/preparar datasets abiertos (MRI/CT)

Ver guÃ­as en `data/README.md`. Resumen rÃ¡pido (Windows PowerShell):

- OpenNeuro ds005533 (T1w/T2w) â†’ pares para Pix2Pix:
  OpciÃ³n A (GitHub Actions â€“ recomendado):
  - En la pestaÃ±a Actions del repo, ejecuta el workflow "Fetch BIDS pairs" (workflow_dispatch)
    con dataset=ds005533, version=1.0.0, max_pairs=3. Esto descargarÃ¡ T1w/T2w y subirÃ¡ PNGs a `data/paired_mri/`.
  
  OpciÃ³n B (local):
  1) Instala OpenNeuro CLI (requiere Node.js):
     npm install -g openneuro-cli
  2) Descarga solo anat/T1w y T2w:
     powershell -ExecutionPolicy Bypass -File scripts/download_openneuro_ds005533.ps1
  3) Convierte 3 pares a PNG 256x256:
     python scripts/prepare_bids_pairs.py --ds_root data/openneuro/ds005533 --out_root data/paired_mri --max_pairs 3

- IXI Brain MRI (T1/T2 â†’ pares para Pix2Pix):

```powershell
python -m src.data.datasets ixi_pairs --ixi_root "C:\\path\\to\\IXI" --out_root data/paired_mri --img_size 256 --take_slices 1
```

- Chest CT (e.g., MosMedData â†’ dominio B para CycleGAN):

```powershell
python -m src.data.datasets ct_slices --ct_root "C:\\path\\to\\CT_NIfTI" --out_root data/unpaired_ct --img_size 256 --take_slices 3
```

Luego ajusta las rutas en los notebooks 03 y 04 si usas una estructura distinta.

### 4. Ejecutar Notebooks

```powershell
jupyter notebook
```

Recomendamos seguir el orden:
1. `01_introduction_mri.ipynb` - MONAI: carga y preprocesamiento IXI (3D â†’ 2D)
2. `02_gans_basics.ipynb` - Entrenar DCGAN desde cero
3. `03_pix2pix_mri.ipynb` - T1â†’T2 con Pix2Pix (usa `data/paired_mri`)
4. `04_cyclegan_ct_mri.ipynb` - MRIâ†”CT con CycleGAN (usa `data/unpaired_*`)
5. `05_diffusion_xray.ipynb` - Diffusion (DDPM)

---

## ğŸ“š Estructura de la PlÃ¡tica

### 1. IntroducciÃ³n (8 min)
- Retos del flujo clÃ­nico: Diagnostic, Treatment, Prognosis
- Motivaciones computacionales

### 2. Modelos Generativos (12 min)
- **GANs**: DCGAN, Pix2Pix, CycleGAN, StyleGAN
- **Diffusion Models**: DDPM, Latent Diffusion, Medfusion
- **ComparaciÃ³n**: Fidelidad vs. Diversidad

### 3. Estado del Arte (10 min)
- Papers clave 2024-2025
- Medfusion: Diffusion supera GANs en diversidad

### 4. Modalidades (12 min)
- **Brain MRI**: T1â†’T2, Compressed sensing, Synthetic-CT
- **CT**: Low-dose denoising, Artifact reduction
- **Chest X-ray**: Data augmentation, Super-resolution

### 5. Demo PrÃ¡ctica (10 min)
- Notebooks interactivos con medigan y MONAI
- GeneraciÃ³n multi-modalidad

### 6. Riesgos (8 min)
- Hallucinations, Mode collapse
- ValidaciÃ³n clÃ­nica insuficiente
- Bias y reproducibilidad

---

## ğŸ§ª Demos y Scripts

### Gradio: Pix2Pix MRI T1â†’T2
- Lanza una UI mÃ­nima para cargar una T1 (PNG/JPG) y generar T2.
- Requiere un checkpoint del generador (por ejemplo, entrenado con `scripts/train_pix2pix.py`).

```powershell
# Ejemplo
python apps/pix2pix_demo.py --checkpoint ckpts/pix2pix/G_best.pt --device cpu --port 7860
```

### Entrenamiento por script (Pix2Pix)
- Configurable vÃ­a YAML en `configs/pix2pix.yaml`.

```powershell
python scripts/train_pix2pix.py --config configs/pix2pix.yaml
```

Salida: checkpoints en `ckpts/pix2pix/` y mÃ©tricas en consola.

---

## ğŸ› ï¸ Herramientas Utilizadas

### Frameworks Principales

- **[MONAI](https://monai.io/)**: Framework PyTorch para medical imaging
- **[medigan](https://github.com/RichardObi/medigan)**: 21+ modelos pre-entrenados
- **[TorchIO](https://github.com/fepegar/torchio)**: Preprocesamiento 3D/4D
- **PyTorch 2.0+**: Deep learning framework

### Datasets PÃºblicos

- **[fastMRI](https://fastmri.org/)**: MRI reconstruction challenge
- **[BraTS](https://www.med.upenn.edu/cbica/brats/)**: Brain tumor segmentation
- **[ChestX-ray14](https://nihcc.app.box.com/v/ChestXray-NIHCC)**: 112K chest X-rays
- **[IXI Dataset](https://brain-development.org/ixi-dataset/)**: Brain MRI multi-modal

---

## ğŸ““ Notebooks Detallados

### `01_introduction.ipynb`
**Objetivo**: Familiarizarse con datos mÃ©dicos  
**Contenido**:
- Cargar imÃ¡genes DICOM y NIfTI
- VisualizaciÃ³n 3D de MRI y CT
- EstadÃ­sticas de datasets mÃ©dicos
- DesafÃ­os: Desbalance de clases, tamaÃ±o reducido

**DuraciÃ³n estimada**: 20 min

---

### `02_gans_basics.ipynb`
**Objetivo**: Implementar DCGAN desde cero  
**Contenido**:
- Arquitectura Generator y Discriminator
- Training loop con adversarial loss
- Generar chest X-rays sintÃ©ticos
- MÃ©tricas: FID, IS
- Detectar mode collapse

**DuraciÃ³n estimada**: 45 min

**CÃ³digo ejemplo**:
```python
# Generator architecture
generator = nn.Sequential(
    nn.ConvTranspose2d(latent_dim, 512, 4, 1, 0),
    nn.BatchNorm2d(512),
    nn.ReLU(True),
    # ... mÃ¡s capas
)

# Training loop
for epoch in range(num_epochs):
    for real_images, _ in dataloader:
        # Train Discriminator
        loss_D = train_discriminator(real_images, generator, discriminator)
        
        # Train Generator
        loss_G = train_generator(generator, discriminator)
```

---

### `03_pix2pix_mri.ipynb`
**Objetivo**: SÃ­ntesis T1â†’T2 en Brain MRI  
**Contenido**:
- Cargar pares aligned de IXI dataset
- Implementar Pix2Pix (U-Net + PatchGAN)
- L1 + adversarial loss
- Evaluar con SSIM, PSNR
- Comparar con ground truth

**DuraciÃ³n estimada**: 60 min

**Dataset**: IXI Brain MRI (T1, T2, PD)

---

### `04_cyclegan_ct_mri.ipynb`
**Objetivo**: TraducciÃ³n unpaired MRIâ†”CT  
**Contenido**:
- CycleGAN architecture (2 generators, 2 discriminators)
- Cycle consistency loss
- Synthetic-CT generation
- Evaluar MAE en Hounsfield Units (HU)

**DuraciÃ³n estimada**: 60 min

**AplicaciÃ³n**: Radioterapia planning sin CT real

---

### `05_diffusion_xray.ipynb`
**Objetivo**: Generar chest X-rays con Diffusion Models  
**Contenido**:
- DDPM forward/reverse process
- Entrenar denoising U-Net
- Conditional generation (por patologÃ­a)
- Comparar diversidad vs. GANs (Precision-Recall)

**DuraciÃ³n estimada**: 90 min

**Dataset**: ChestX-ray14 subset

---

### `06_medigan_demo.ipynb`
**Objetivo**: Demo rÃ¡pida con modelos pre-entrenados  
**Contenido**:
- Instalar medigan
- Listar 21+ modelos disponibles
- Generar:
  - MamografÃ­as (C-DCGAN)
  - Chest X-rays (DCGAN)
  - Brain MRI (si disponible)
- Visualizar resultados
- Explorar latent space

**DuraciÃ³n estimada**: 15 min

**Ventaja**: Sin entrenamiento, resultados inmediatos

---

## ğŸ¯ Ejercicios PrÃ¡cticos

### Ejercicio 1: Data Augmentation para ClasificaciÃ³n
**Objetivo**: Mejorar clasificador de neumotÃ³rax con datos sintÃ©ticos

**Pasos**:
1. Entrenar clasificador baseline (ResNet-18) con datos reales (N=500)
2. Generar 1000 X-rays sintÃ©ticos con DCGAN
3. Re-entrenar con datos reales + sintÃ©ticos
4. Comparar accuracy, precision, recall

**Pregunta**: Â¿CuÃ¡ntos datos sintÃ©ticos son Ã³ptimos? (0%, 50%, 100%, 200%)

---

### Ejercicio 2: EvaluaciÃ³n de Calidad
**Objetivo**: Implementar mÃ©tricas de evaluaciÃ³n

**Tareas**:
- Calcular FID entre imÃ¡genes reales y sintÃ©ticas
- Implementar Precision-Recall para GANs
- Evaluar SSIM/PSNR para reconstrucciÃ³n
- Comparar DCGAN vs. StyleGAN vs. Diffusion

---

### Ejercicio 3: DetecciÃ³n de Hallucinations
**Objetivo**: Identificar estructuras anatÃ³micas falsas

**MÃ©todo**:
- Generar 100 brain MRIs sintÃ©ticos
- Usar segmentador pre-entrenado (FreeSurfer)
- Detectar estructuras anatÃ³micamente imposibles
- Filtrar imÃ¡genes con hallucinations

---

## ğŸ§ª ValidaciÃ³n y MÃ©tricas (TorchMetrics)

Este repositorio usa TorchMetrics para evaluar la calidad de los modelos generativos:

- DCGAN (02_gans_basics.ipynb): FrechetInceptionDistance (FID) e InceptionScore (IS)
- Pix2Pix (03_pix2pix_mri.ipynb): StructuralSimilarityIndexMeasure (SSIM) y PeakSignalNoiseRatio (PSNR) contra ground truth
- CycleGAN (04_cyclegan_ct_mri.ipynb): SSIM y PSNR sobre la consistencia de ciclo (Aâ†’Bâ†’A y Bâ†’Aâ†’B)
- Diffusion (05_diffusion_xray.ipynb): FID entre muestras generadas y el set de validaciÃ³n

Salida y guardado de resultados:
- Las figuras y grids se guardan automÃ¡ticamente en `outputs/<modelo>/`:
  - `outputs/dcgan/metrics.png`, `outputs/dcgan/samples.png`
  - `outputs/pix2pix/metrics.png`, `outputs/pix2pix/val_grid.png`
  - `outputs/cyclegan/metrics.png`, `outputs/cyclegan/a_b_a.png`, `outputs/cyclegan/b_a_b.png`
  - `outputs/diffusion/metrics.png`, `outputs/diffusion/samples.png`

InstalaciÃ³n rÃ¡pida de mÃ©tricas:

```bash
pip install torchmetrics
```

Nota: Para FID/IS, TorchMetrics descarga/usa un Inception por defecto. Las imÃ¡genes se re-escalan a [0,1] en el notebook antes de evaluar.

---

## ğŸ“Š Resultados Esperados

Al completar este repositorio, los estudiantes podrÃ¡n:

âœ… **Implementar** GANs y Diffusion Models desde cero  
âœ… **Entrenar** modelos para MRI, CT, y X-ray synthesis  
âœ… **Evaluar** calidad con FID, IS, SSIM, y mÃ©tricas clÃ­nicas  
âœ… **Detectar** problemas como mode collapse y hallucinations  
âœ… **Aplicar** modelos pre-entrenados con medigan  
âœ… **Entender** trade-offs: Fidelidad vs. Diversidad vs. Velocidad  

---

## ğŸ“– Referencias Principales

### Papers Fundamentales

**GANs**:
- Goodfellow et al. (2014). "Generative Adversarial Networks". NeurIPS.
- Radford et al. (2016). "Unsupervised Representation Learning with DCGANs". ICLR.
- Isola et al. (2017). "Image-to-Image Translation with Conditional GANs". CVPR.
- Zhu et al. (2017). "Unpaired Image-to-Image Translation using CycleGANs". ICCV.
- Karras et al. (2019). "A Style-Based Generator Architecture for GANs". CVPR.

**Diffusion Models**:
- Ho et al. (2020). "Denoising Diffusion Probabilistic Models". NeurIPS.
- Rombach et al. (2022). "High-Resolution Image Synthesis with Latent Diffusion". CVPR.
- Friedrich et al. (2023). "Medfusion: Latent DDPMs vs GANs for Medical Imaging". Scientific Reports.

**Medical Imaging Reviews**:
- Oulmalme et al. (2025). "Systematic Review of Generative AI for Medical Image Enhancement".
- Ibrahim et al. (2025). "Generative AI for Synthetic Data Across Multiple Modalities".

Ver lista completa en [`docs/REFERENCIAS.md`](docs/REFERENCIAS.md)

---

## ğŸ¤ Contribuciones

Â¡Las contribuciones son bienvenidas! Si encuentras bugs o tienes sugerencias:

1. Fork el repositorio
2. Crea una branch (`git checkout -b feature/nueva-funcionalidad`)
3. Commit cambios (`git commit -m 'Agregar nueva funcionalidad'`)
4. Push a la branch (`git push origin feature/nueva-funcionalidad`)
5. Abre un Pull Request

---

## ğŸ“§ Contacto

- **Instructor**: Maria Julieta Mateos
- **Email**: julieta8a3@gmail.com


---

## ğŸ“„ Licencia

Este proyecto estÃ¡ bajo la licencia MIT. Ver [`LICENSE`](LICENSE) para mÃ¡s detalles.

---

## ğŸ™ Agradecimientos

- **MONAI Consortium** por el framework
- **medigan** team por modelos pre-entrenados
- **PyTorch** community
- Datasets pÃºblicos: fastMRI, BraTS, ChestX-ray14, IXI

---

## ğŸ”— Enlaces Ãštiles

- [DocumentaciÃ³n MONAI](https://docs.monai.io/)
- [medigan GitHub](https://github.com/RichardObi/medigan)
- [fastMRI Challenge](https://fastmri.org/)
- [Grand Challenges](https://grand-challenge.org/)
- [Papers with Code - Medical Imaging](https://paperswithcode.com/area/medical)

---

**Ãšltima actualizaciÃ³n**: Noviembre 2025
