{
 "cells": [
  {"cell_type": "markdown", "metadata": {}, "source": ["# 04_cyclegan_ct_mri.ipynb — MRI↔CT translation\n\nTraducción no pareada entre dominios con CycleGAN (MRI ↔ CT).\n"]},
  {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["import sys\nif '.' not in sys.path: sys.path.append('.')\nimport torch\nfrom torch import nn, optim\nfrom torch.utils.data import Dataset, DataLoader\nfrom torchvision import transforms\nfrom PIL import Image\nfrom pathlib import Path\nfrom src.models.cyclegan import ResnetGenerator, NLayerDiscriminator\nfrom src.utils.visualization import show_images\n"]},
  {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["class UnpairedDataset(Dataset):\n    def __init__(self, rootA, rootB, img_size=256):\n        self.A = sorted(Path(rootA).glob('*.png'))\n        self.B = sorted(Path(rootB).glob('*.png'))\n        self.tf = transforms.Compose([transforms.Grayscale(1), transforms.Resize((img_size,img_size)), transforms.ToTensor(), transforms.Normalize([0.5],[0.5])])\n    def __len__(self): return max(len(self.A), len(self.B))\n    def __getitem__(self, idx):\n        a = self.tf(Image.open(self.A[idx % len(self.A)]).convert('L'))\n        b = self.tf(Image.open(self.B[idx % len(self.B)]).convert('L'))\n        return a, b\n\n# TODO: cambia estas rutas a tus carpetas MRI y CT\nrootA, rootB = 'data/unpaired_mri', 'data/unpaired_ct'\nimg_size=256; batch_size=2\ntrain_ds = UnpairedDataset(rootA, rootB, img_size)\ntrain_dl = DataLoader(train_ds, batch_size=batch_size, shuffle=True, num_workers=2)\n\nG_AB = ResnetGenerator(1,1); G_BA = ResnetGenerator(1,1)\nD_A = NLayerDiscriminator(1); D_B = NLayerDiscriminator(1)\ndevice = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\nG_AB.to(device); G_BA.to(device); D_A.to(device); D_B.to(device)\nopt_g = optim.Adam(list(G_AB.parameters())+list(G_BA.parameters()), lr=2e-4, betas=(0.5,0.999))\nopt_d = optim.Adam(list(D_A.parameters())+list(D_B.parameters()), lr=2e-4, betas=(0.5,0.999))\ncycle = nn.L1Loss(); ident = nn.L1Loss(); bce = nn.BCEWithLogitsLoss()\n"]},
  {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["for epoch in range(1):\n    for i, (a, b) in enumerate(train_dl):\n        a, b = a.to(device), b.to(device)\n        # ---- Train D ----\n        opt_d.zero_grad()\n        fake_b = G_AB(a).detach()\n        fake_a = G_BA(b).detach()\n        loss_d = bce(D_A(a), torch.ones_like(D_A(a))) + bce(D_A(fake_a), torch.zeros_like(D_A(fake_a))) \
               + bce(D_B(b), torch.ones_like(D_B(b))) + bce(D_B(fake_b), torch.zeros_like(D_B(fake_b)))\n        loss_d.backward(); opt_d.step()\n        # ---- Train G (adversarial + cycle + identity) ----\n        opt_g.zero_grad()\n        fake_b = G_AB(a); fake_a = G_BA(b)\n        rec_a = G_BA(fake_b); rec_b = G_AB(fake_a)\n        adv = bce(D_B(fake_b), torch.ones_like(D_B(fake_b))) + bce(D_A(fake_a), torch.ones_like(D_A(fake_a)))\n        cyc = cycle(rec_a, a) + cycle(rec_b, b)\n        idt = ident(G_AB(b), b) + ident(G_BA(a), a)\n        loss_g = adv + 10*cyc + 0.5*idt\n        loss_g.backward(); opt_g.step()\n        if i % 50 == 0:\n            print(f'E{epoch} I{i} | D {float(loss_d):.3f} G {float(loss_g):.3f}')\n            with torch.no_grad():\n                show_images(torch.cat([a[:4], fake_b[:4], rec_a[:4]], dim=0), nrow=4, title='A->B->A')\n                show_images(torch.cat([b[:4], fake_a[:4], rec_b[:4]], dim=0), nrow=4, title='B->A->B')\n"]}
 ],
 "metadata": {"kernelspec": {"display_name": "Python 3", "language": "python", "name": "python3"}, "language_info": {"name": "python", "version": "3.10"}},
 "nbformat": 4,
 "nbformat_minor": 5
}
