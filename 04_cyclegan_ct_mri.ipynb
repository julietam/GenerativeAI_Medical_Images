{
    "cells":  [
                  {
                      "cell_type":  "markdown",
                      "metadata":  {

                                   },
                      "source":  [
                                     "# 04_cyclegan_ct_mri.ipynb â€” MRIâ†”CT translation\n\nTraducciÃ³n no pareada entre dominios con CycleGAN (MRI â†” CT).\n"
                                 ]
                  },
                  {
                      "cell_type":  "code",
                      "execution_count":  null,
                      "metadata":  {

                                   },
                      "outputs":  [

                                  ],
                      "source":  [
                                     "import sys\nif \u0027.\u0027 not in sys.path: sys.path.append(\u0027.\u0027)\nimport torch\nfrom torch import nn, optim\nfrom torch.utils.data import Dataset, DataLoader\nfrom torchvision import transforms\nfrom PIL import Image\nfrom pathlib import Path\nfrom src.models.cyclegan import ResnetGenerator, NLayerDiscriminator\nfrom src.utils.visualization import show_images\n"
                                 ]
                  },
                  {
                      "cell_type":  "code",
                      "execution_count":  null,
                      "metadata":  {

                                   },
                      "outputs":  [

                                  ],
                      "source":  [
                                     "class UnpairedDataset(Dataset):\n    def __init__(self, rootA, rootB, img_size=256):\n        self.A = sorted(Path(rootA).glob(\u0027*.png\u0027))\n        self.B = sorted(Path(rootB).glob(\u0027*.png\u0027))\n        self.tf = transforms.Compose([transforms.Grayscale(1), transforms.Resize((img_size,img_size)), transforms.ToTensor(), transforms.Normalize([0.5],[0.5])])\n    def __len__(self): return max(len(self.A), len(self.B))\n    def __getitem__(self, idx):\n        a = self.tf(Image.open(self.A[idx % len(self.A)]).convert(\u0027L\u0027))\n        b = self.tf(Image.open(self.B[idx % len(self.B)]).convert(\u0027L\u0027))\n        return a, b\n\n# TODO: cambia estas rutas a tus carpetas MRI y CT\nrootA, rootB = \u0027data/sample_unpaired_mri\u0027, \u0027data/sample_unpaired_ct\u0027\n# Autogenera datos de muestra si no existen\nfrom pathlib import Path\nimport subprocess, sys\nif not any(Path(rootA).glob(\u0027*.png\u0027)) or not any(Path(rootB).glob(\u0027*.png\u0027)):\n    try:\n        subprocess.run([sys.executable, \u0027scripts/make_sample_data.py\u0027], check=False)\n    except Exception as e:\n        print(\u0027Warning: could not generate sample data:\u0027, e)\nimg_size=256; batch_size=2\ntrain_ds = UnpairedDataset(rootA, rootB, img_size)\ntrain_dl = DataLoader(train_ds, batch_size=batch_size, shuffle=True, num_workers=2)\n\nG_AB = ResnetGenerator(1,1); G_BA = ResnetGenerator(1,1)\nD_A = NLayerDiscriminator(1); D_B = NLayerDiscriminator(1)\ndevice = torch.device(\u0027cuda\u0027 if torch.cuda.is_available() else \u0027cpu\u0027)\nG_AB.to(device); G_BA.to(device); D_A.to(device); D_B.to(device)\nopt_g = optim.Adam(list(G_AB.parameters())+list(G_BA.parameters()), lr=2e-4, betas=(0.5,0.999))\nopt_d = optim.Adam(list(D_A.parameters())+list(D_B.parameters()), lr=2e-4, betas=(0.5,0.999))\ncycle = nn.L1Loss(); ident = nn.L1Loss(); bce = nn.BCEWithLogitsLoss()\n"
                                 ]
                  },
                  {
                      "cell_type":  "code",
                      "execution_count":  null,
                      "metadata":  {

                                   },
                      "outputs":  [

                                  ],
                      "source":  [
                                     "for epoch in range(1):\n    for i, (a, b) in enumerate(train_dl):\n        a, b = a.to(device), b.to(device)\n        # ---- Train D ----\n        opt_d.zero_grad()\n        fake_b = G_AB(a).detach()\n        fake_a = G_BA(b).detach()\n        loss_d = bce(D_A(a), torch.ones_like(D_A(a))) + bce(D_A(fake_a), torch.zeros_like(D_A(fake_a))) \\\r\n               + bce(D_B(b), torch.ones_like(D_B(b))) + bce(D_B(fake_b), torch.zeros_like(D_B(fake_b)))\n        loss_d.backward(); opt_d.step()\n        # ---- Train G (adversarial + cycle + identity) ----\n        opt_g.zero_grad()\n        fake_b = G_AB(a); fake_a = G_BA(b)\n        rec_a = G_BA(fake_b); rec_b = G_AB(fake_a)\n        adv = bce(D_B(fake_b), torch.ones_like(D_B(fake_b))) + bce(D_A(fake_a), torch.ones_like(D_A(fake_a)))\n        cyc = cycle(rec_a, a) + cycle(rec_b, b)\n        idt = ident(G_AB(b), b) + ident(G_BA(a), a)\n        loss_g = adv + 10*cyc + 0.5*idt\n        loss_g.backward(); opt_g.step()\n        if i % 50 == 0:\n            print(f\u0027E{epoch} I{i} | D {float(loss_d):.3f} G {float(loss_g):.3f}\u0027)\n            with torch.no_grad():\n                show_images(torch.cat([a[:4], fake_b[:4], rec_a[:4]], dim=0), nrow=4, title=\u0027A-\u003eB-\u003eA\u0027)\n                show_images(torch.cat([b[:4], fake_a[:4], rec_b[:4]], dim=0), nrow=4, title=\u0027B-\u003eA-\u003eB\u0027)\n"
                                 ]
                  },
                  {
                      "cell_type":  "code",
                      "execution_count":  null,
                      "metadata":  {

                                   },
                      "outputs":  [

                                  ],
                      "source":  [
                                     "from src.utils.visualization import plot_curves, show_images\n",
                                     "from torch.utils.data import random_split\n",
                                     "from torchmetrics.image import StructuralSimilarityIndexMeasure, PeakSignalNoiseRatio\n",
                                     "import os, torch\n",
                                     "device = torch.device(\u0027cuda\u0027 if torch.cuda.is_available() else \u0027cpu\u0027)\n",
                                     "G_AB.eval(); G_BA.eval()\n",
                                     "full_ds = UnpairedDataset(rootA, rootB, img_size)\n",
                                     "n_val = max(1, int(0.1*len(full_ds)))\n",
                                     "n_train = len(full_ds)-n_val\n",
                                     "_, val_ds = random_split(full_ds, [n_train, n_val])\n",
                                     "val_dl = DataLoader(val_ds, batch_size=batch_size, shuffle=False, num_workers=2)\n",
                                     "ssim_metric = StructuralSimilarityIndexMeasure(data_range=1.0).to(device)\n",
                                     "psnr_metric = PeakSignalNoiseRatio(data_range=1.0).to(device)\n",
                                     "ssim_A, psnr_A, ssim_B, psnr_B = [], [], [], []\n",
                                     "with torch.no_grad():\n",
                                     "    for a,b in val_dl:\n",
                                     "        a,b = a.to(device), b.to(device)\n",
                                     "        fake_b = G_AB(a); rec_a = G_BA(fake_b)\n",
                                     "        fake_a = G_BA(b); rec_b = G_AB(fake_a)\n",
                                     "        ra01, a01 = (rec_a+1)/2, (a+1)/2\n",
                                     "        rb01, b01 = (rec_b+1)/2, (b+1)/2\n",
                                     "        ssim_A.append(ssim_metric(ra01, a01).item()); psnr_A.append(psnr_metric(ra01, a01).item())\n",
                                     "        ssim_B.append(ssim_metric(rb01, b01).item()); psnr_B.append(psnr_metric(rb01, b01).item())\n",
                                     "h = {\n",
                                     " \u0027cycle_ssim_A\u0027: [float(sum(ssim_A)/len(ssim_A)) if ssim_A else 0.0],\n",
                                     " \u0027cycle_psnr_A\u0027: [float(sum(psnr_A)/len(psnr_A)) if psnr_A else 0.0],\n",
                                     " \u0027cycle_ssim_B\u0027: [float(sum(ssim_B)/len(ssim_B)) if ssim_B else 0.0],\n",
                                     " \u0027cycle_psnr_B\u0027: [float(sum(psnr_B)/len(psnr_B)) if psnr_B else 0.0],\n",
                                     "}\n",
                                     "print(h)\n",
                                     "os.makedirs(\u0027outputs/cyclegan\u0027, exist_ok=True)\n",
                                     "plot_curves(h, title=\u0027CycleGAN validation (TorchMetrics)\u0027, save_path=\u0027outputs/cyclegan/metrics.png\u0027)\n",
                                     "if len(val_dl)\u003e0:\n",
                                     "    a,b = next(iter(val_dl))\n",
                                     "    a,b = a.to(device), b.to(device)\n",
                                     "    fb = G_AB(a); ra = G_BA(fb)\n",
                                     "    fa = G_BA(b); rb = G_AB(fa)\n",
                                     "    show_images(torch.cat([a[:4], fb[:4], ra[:4]], dim=0), nrow=4, title=\u0027A-\u003eB-\u003eA (val)\u0027, save_path=\u0027outputs/cyclegan/a_b_a.png\u0027)\n",
                                     "    show_images(torch.cat([b[:4], fa[:4], rb[:4]], dim=0), nrow=4, title=\u0027B-\u003eA-\u003eB (val)\u0027, save_path=\u0027outputs/cyclegan/b_a_b.png\u0027)\n"
                                 ]
                  }
              ],
    "metadata":  {
                     "kernelspec":  {
                                        "display_name":  "Python 3",
                                        "language":  "python",
                                        "name":  "python3"
                                    },
                     "language_info":  {
                                           "name":  "python",
                                           "version":  "3.10"
                                       }
                 },
    "nbformat":  4,
    "nbformat_minor":  5
}
