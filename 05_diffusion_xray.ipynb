{
 "cells": [
  {"cell_type": "markdown", "metadata": {}, "source": ["# 05_diffusion_xray.ipynb — Diffusion model training\n\nEntrenamiento mínimo de DDPM para imágenes de rayos X (64x64, 1 canal).\n"]},
  {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["import sys\nif '.' not in sys.path: sys.path.append('.')\nimport torch\nfrom torch.utils.data import DataLoader\nfrom torchvision import datasets, transforms\nfrom src.models.diffusion import SimpleUNet, DDPM\nfrom src.utils.visualization import show_images\n"]},
  {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\nimg_size = 64\nbatch_size = 32\n# TODO: reemplazar por dataset de rayos X (e.g., RSNA, NIH)\ndataset = datasets.FakeData(size=512, image_size=(1,img_size,img_size), transform=transforms.Compose([transforms.ToTensor(), transforms.Normalize([0.5],[0.5])]))\nloader = DataLoader(dataset, batch_size=batch_size, shuffle=True, num_workers=2)\nmodel = SimpleUNet(channels=1, base=32).to(device)\nddpm = DDPM(model, img_size=img_size, channels=1, timesteps=200).to(device)\nopt = torch.optim.Adam(model.parameters(), lr=2e-4)\n"]},
  {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["for epoch in range(1):\n    for x, _ in loader:\n        x = (x - 0.5) / 0.5\n        x = x.to(device)\n        t = torch.randint(0, ddpm.T, (x.size(0),), device=device)\n        loss, _ = ddpm.p_losses(x, t)\n        opt.zero_grad(); loss.backward(); opt.step()\n    print('epoch', epoch, 'loss', float(loss))\n    with torch.no_grad():\n        samples = ddpm.sample(16, device=device)\n        show_images(samples.cpu(), nrow=4, title=f'Epoch {epoch}')\n"]},
  {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": [
   "from src.utils.metrics import fid\n",
   "from src.utils.visualization import plot_curves\n",
   "from torchvision import models, transforms as T\n",
   "from torch.utils.data import DataLoader\n",
   "import os, torch\n",
   "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
   "# build validation set (proxy)\n",
   "full_ds = datasets.FakeData(size=256, image_size=(1,img_size,img_size), transform=transforms.Compose([transforms.ToTensor(), transforms.Normalize([0.5],[0.5])]))\n",
   "val_dl = DataLoader(full_ds, batch_size=batch_size, shuffle=False, num_workers=2)\n",
   "try:\n",
   "    resnet = models.resnet18(weights=models.ResNet18_Weights.DEFAULT).eval().to(device)\n",
   "    feat = torch.nn.Sequential(*(list(resnet.children())[:-1]))\n",
   "except Exception as e:\n",
   "    print('Warning: could not load pretrained weights:', e)\n",
   "    resnet = models.resnet18(weights=None).eval().to(device)\n",
   "    feat = torch.nn.Sequential(*(list(resnet.children())[:-1]))\n",
   "prep = T.Compose([T.Resize((224,224)), T.Lambda(lambda t: t.repeat(1,3,1,1) if t.size(1)==1 else t)])\n",
   "def get_feats(x):\n",
   "    x = (x+1)/2 if x.min()<0 else x\n",
   "    x = prep(x)\n",
   "    with torch.no_grad():\n",
   "        f = feat(x).flatten(1)\n",
   "    return f\n",
   "# collect real feats\n",
   "real_feats = []\n",
   "for xr,_ in val_dl:\n",
   "    xr = xr.to(device)\n",
   "    real_feats.append(get_feats(xr))\n",
   "real_feats = torch.cat(real_feats, dim=0)\n",
   "# generate and collect feats\n",
   "with torch.no_grad():\n",
   "    fake = ddpm.sample(real_feats.size(0), device=device)\n",
   "fake_feats = []\n",
   "for i in range(0, fake.size(0), batch_size):\n",
   "    fake_feats.append(get_feats(fake[i:i+batch_size]))\n",
   "fake_feats = torch.cat(fake_feats, dim=0)\n",
   "fid_val = fid(real_feats, fake_feats)\n",
   "print({'FID_proxy': fid_val})\n",
   "plot_curves({'FID_proxy':[fid_val]}, title='Diffusion validation (FID proxy)')\n"
  ]}
 ],
 "metadata": {"kernelspec": {"display_name": "Python 3", "language": "python", "name": "python3"}, "language_info": {"name": "python", "version": "3.10"}},
 "nbformat": 4,
 "nbformat_minor": 5
}
