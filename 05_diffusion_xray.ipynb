{
 "cells": [
  {"cell_type": "markdown", "metadata": {}, "source": ["# 05_diffusion_xray.ipynb — Diffusion model training\n\nEntrenamiento mínimo de DDPM para imágenes de rayos X (64x64, 1 canal).\n"]},
  {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["import sys\nif '.' not in sys.path: sys.path.append('.')\nimport torch\nfrom torch.utils.data import DataLoader\nfrom torchvision import datasets, transforms\nfrom src.models.diffusion import SimpleUNet, DDPM\nfrom src.utils.visualization import show_images\n"]},
  {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\nimg_size = 64\nbatch_size = 32\n# Usa PNGs locales si existen (p.ej., data/sample_unpaired_ct); si no, FakeData\nfrom pathlib import Path\nfrom PIL import Image\nfrom torch.utils.data import Dataset\nfrom torchvision import transforms\nclass PNGFolderDataset(Dataset):\n    def __init__(self, root, img_size):\n        self.paths = sorted(Path(root).glob('*.png'))\n        self.tf = transforms.Compose([\n            transforms.Grayscale(num_output_channels=1),\n            transforms.Resize((img_size, img_size)),\n            transforms.ToTensor(),\n            transforms.Normalize([0.5], [0.5]),\n        ])\n    def __len__(self): return len(self.paths)\n    def __getitem__(self, i):\n        return self.tf(Image.open(self.paths[i]).convert('L')), 0\nroot_ct = Path('data/sample_unpaired_ct')\nif not any(root_ct.glob('*.png')):\n    # intenta generar muestras\n    import subprocess, sys\n    try: subprocess.run([sys.executable, 'scripts/make_sample_data.py'], check=False)\n    except Exception as e: print('Warning: sample gen failed:', e)\nif any(root_ct.glob('*.png')):\n    dataset = PNGFolderDataset(root_ct, img_size)\nelse:\n    dataset = datasets.FakeData(size=512, image_size=(1,img_size,img_size), transform=transforms.Compose([transforms.ToTensor(), transforms.Normalize([0.5],[0.5])]))\nloader = DataLoader(dataset, batch_size=batch_size, shuffle=True, num_workers=2)\nmodel = SimpleUNet(channels=1, base=32).to(device)\nddpm = DDPM(model, img_size=img_size, channels=1, timesteps=200).to(device)\nopt = torch.optim.Adam(model.parameters(), lr=2e-4)\n"]},
  {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["for epoch in range(1):\n    for x, _ in loader:\n        x = (x - 0.5) / 0.5\n        x = x.to(device)\n        t = torch.randint(0, ddpm.T, (x.size(0),), device=device)\n        loss, _ = ddpm.p_losses(x, t)\n        opt.zero_grad(); loss.backward(); opt.step()\n    print('epoch', epoch, 'loss', float(loss))\n    with torch.no_grad():\n        samples = ddpm.sample(16, device=device)\n        show_images(samples.cpu(), nrow=4, title=f'Epoch {epoch}')\n"]},
  {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": [
   "from torchmetrics.image.fid import FrechetInceptionDistance\n",
   "from src.utils.visualization import plot_curves, show_images\n",
   "from torch.utils.data import DataLoader\n",
   "import os, torch\n",
   "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
   "# build validation set\n",
   "full_ds = datasets.FakeData(size=256, image_size=(1,img_size,img_size), transform=transforms.Compose([transforms.ToTensor(), transforms.Normalize([0.5],[0.5])]))\n",
   "val_dl = DataLoader(full_ds, batch_size=batch_size, shuffle=False, num_workers=2)\n",
   "fid = FrechetInceptionDistance(normalize=True).to(device)\n",
   "# real updates\n",
   "for xr,_ in val_dl:\n",
   "    xr = xr.to(device)\n",
   "    xr01 = (xr + 1)/2\n",
   "    fid.update(xr01, real=True)\n",
   "# fake updates\n",
   "with torch.no_grad():\n",
   "    fake = ddpm.sample(len(full_ds), device=device)\n",
   "fake01 = (fake + 1)/2\n",
   "for i in range(0, fake01.size(0), batch_size):\n",
   "    fid.update(fake01[i:i+batch_size], real=False)\n",
   "fid_val = float(fid.compute())\n",
   "print({'FID': fid_val})\n",
   "os.makedirs('outputs/diffusion', exist_ok=True)\n",
   "plot_curves({'FID':[fid_val]}, title='Diffusion validation (TorchMetrics FID)', save_path='outputs/diffusion/metrics.png')\n",
   "show_images(fake[:16].cpu(), nrow=4, title='Diffusion samples (val)', save_path='outputs/diffusion/samples.png')\n"
  ]}
 ],
 "metadata": {"kernelspec": {"display_name": "Python 3", "language": "python", "name": "python3"}, "language_info": {"name": "python", "version": "3.10"}},
 "nbformat": 4,
 "nbformat_minor": 5
}
