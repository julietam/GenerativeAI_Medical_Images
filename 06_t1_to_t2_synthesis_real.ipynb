{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 06_t1_to_t2_synthesis_real.ipynb — T1→T2 con datos reales\n\n",
    "Incluye celdas para: (1) usar solo datos reales (sin fallback), (2) descargar y convertir ds005533 a PNGs pareados, (3) comparar dos modelos (Pix2Pix y MONAI UNet) y (4) tabla de métricas.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Colab setup: clonar repo e instalar dependencias\n",
    "import os, sys, subprocess\n",
    "from pathlib import Path\n",
    "\n",
    "IN_COLAB = False\n",
    "try:\n",
    "    import google.colab  # type: ignore\n",
    "    IN_COLAB = True\n",
    "except Exception:\n",
    "    pass\n",
    "\n",
    "repo_url = \"https://github.com/julietam/GenerativeAI_Medical_Images.git\"\n",
    "workdir = Path(\"/content/GenerativeAI_Medical_Images\") if IN_COLAB else Path.cwd()\n",
    "\n",
    "if IN_COLAB:\n",
    "    if not workdir.exists():\n",
    "        subprocess.run([\"git\", \"clone\", repo_url, str(workdir)], check=True)\n",
    "    else:\n",
    "        subprocess.run([\"git\", \"-C\", str(workdir), \"pull\", \"--ff-only\"], check=False)\n",
    "    os.chdir(workdir)\n",
    "\n",
    "subprocess.run([sys.executable, \"-m\", \"pip\", \"install\", \"-q\", \"-r\", \"requirements.txt\"], check=False)\n",
    "subprocess.run([sys.executable, \"-m\", \"pip\", \"install\", \"-q\", \"torchmetrics\", \"monai\", \"pandas\"], check=False)\n",
    "print(\"Setup done. CWD =\", Path.cwd())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Usar datos reales (sin generar samples) — requiere PNGs en data/paired_mri/T1 y T2\n",
    "from pathlib import Path\n",
    "\n",
    "USE_REAL_ONLY = True\n",
    "paired_root = Path('data/paired_mri')\n",
    "t1_dir = paired_root/'T1'\n",
    "t2_dir = paired_root/'T2'\n",
    "\n",
    "n_t1 = len(list(t1_dir.glob('*.png')))\n",
    "n_t2 = len(list(t2_dir.glob('*.png')))\n",
    "assert n_t1 > 0 and n_t2 > 0, 'No hay PNGs reales en data/paired_mri; ejecuta la celda de conversión ds005533 primero.'\n",
    "print('OK: pares reales detectados:', n_t1, 'T1 y', n_t2, 'T2 en', paired_root)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# (Opcional) Descargar y convertir OpenNeuro ds005533 a PNGs pareados (T1/T2) en data/paired_mri\n",
    "import os, sys, subprocess\n",
    "from pathlib import Path\n",
    "\n",
    "root = Path.cwd()\n",
    "ds_root = root / 'data' / 'ds005533'\n",
    "# Corregir posible typo: si existe ds005333 y no ds005533, usarlo\n",
    "if not ds_root.exists():\n",
    "    typo = root / 'data' / 'ds005333'\n",
    "    if typo.exists(): ds_root = typo\n",
    "out_root = root / 'data' / 'paired_mri'\n",
    "out_root.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "# Instalar git-annex (Colab/Ubuntu)\n",
    "subprocess.run(['apt-get', 'update'], check=False)\n",
    "subprocess.run(['apt-get', 'install', '-y', 'git-annex'], check=False)\n",
    "\n",
    "# Clonar dataset si no existe\n",
    "if not ds_root.exists():\n",
    "    subprocess.run(['git', 'clone', 'https://github.com/OpenNeuroDatasets/ds005533.git', str(ds_root)], check=True)\n",
    "\n",
    "# Configurar annex\n",
    "subprocess.run(['git', '-C', str(ds_root), 'config', 'user.name', 'colab'], check=False)\n",
    "subprocess.run(['git', '-C', str(ds_root), 'config', 'user.email', 'colab@example.com'], check=False)\n",
    "subprocess.run(['git', '-C', str(ds_root), 'annex', 'init'], check=False)\n",
    "for r in ['openneuro', 's3-PUBLIC', 'gins3', 'aws', 'web']:\n",
    "    subprocess.run(['git', '-C', str(ds_root), 'annex', 'enableremote', r], check=False)\n",
    "# Localiza archivos T1/T2 y trae contenido explícitamente (sin globs del shell)\n",
    "t1s = sorted(ds_root.glob('sub-*/**/anat/*_T1w.nii*'))\n",
    "t2s = sorted(ds_root.glob('sub-*/**/anat/*_T2w.nii*'))\n",
    "rel_list = [str(p.relative_to(ds_root)) for p in (t1s[:60] + t2s[:60])]\n",
    "if rel_list:\n",
    "    subprocess.run(['git', '-C', str(ds_root), 'annex', 'get', *rel_list], check=False)\n",
    "print('NIfTI encontrados: T1=', len(t1s), 'T2=', len(t2s))\n",
    "\n",
    "# Convertir hasta 20 pares con cortes centro±1\n",
    "subprocess.run([\n",
    "    sys.executable, 'scripts/prepare_bids_pairs.py',\n",
    "    '--ds_root', str(ds_root),\n",
    "    '--out_root', str(out_root),\n",
    "    '--max_pairs', '20',\n",
    "    '--slice_offsets', '0,-1,1',\n",
    "], check=True)\n",
    "\n",
    "print('T1 PNGs:', len(list((out_root/'T1').glob('*.png'))),\n",
    "      'T2 PNGs:', len(list((out_root/'T2').glob('*.png'))),\n",
    "      '->', out_root)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data paths (respeta USE_REAL_ONLY)\n",
    "from pathlib import Path\n",
    "import subprocess, sys\n",
    "\n",
    "paired_root = Path('data/paired_mri')\n",
    "sample_root = Path('data/sample_mri_pairs')\n",
    "t1_dir = paired_root/'T1'\n",
    "t2_dir = paired_root/'T2'\n",
    "\n",
    "if 'USE_REAL_ONLY' in globals() and USE_REAL_ONLY:\n",
    "    n_t1 = len(list(t1_dir.glob('*.png')))\n",
    "    n_t2 = len(list(t2_dir.glob('*.png')))\n",
    "    assert n_t1 > 0 and n_t2 > 0, 'No hay PNGs reales en data/paired_mri; ejecuta la celda de conversión primero.'\n",
    "else:\n",
    "    if not any(t1_dir.glob('*.png')) or not any(t2_dir.glob('*.png')):\n",
    "        try:\n",
    "            subprocess.run([sys.executable, 'scripts/make_sample_data.py'], check=False)\n",
    "        except Exception as e:\n",
    "            print('Warning: could not generate sample data:', e)\n",
    "        if any((sample_root/'T1').glob('*.png')) and any((sample_root/'T2').glob('*.png')):\n",
    "            paired_root = sample_root\n",
    "            t1_dir = sample_root/'T1'\n",
    "            t2_dir = sample_root/'T2'\n",
    "\n",
    "print('Using pairs from', paired_root)\n",
    "print('Found', len(list(t1_dir.glob('*.png'))), 'T1 and', len(list(t2_dir.glob('*.png'))), 'T2')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dataset y transforms (grayscale → [-1,1])\n",
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torchvision import transforms\n",
    "from PIL import Image\n",
    "\n",
    "img_size = 256\n",
    "tf = transforms.Compose([\n",
    "    transforms.Grayscale(num_output_channels=1),\n",
    "    transforms.Resize((img_size, img_size)),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize([0.5],[0.5]),\n",
    "])\n",
    "\n",
    "class PairedMRIDataset(Dataset):\n",
    "    def __init__(self, root):\n",
    "        root = Path(root)\n",
    "        self.a = sorted((root/'T1').glob('*.png'))\n",
    "        self.b = sorted((root/'T2').glob('*.png'))\n",
    "        assert len(self.a) == len(self.b) and len(self.a) > 0, 'Need paired PNGs under T1/ and T2/'\n",
    "    def __len__(self): return len(self.a)\n",
    "    def __getitem__(self, i):\n",
    "        A = tf(Image.open(self.a[i]).convert('L'))\n",
    "        B = tf(Image.open(self.b[i]).convert('L'))\n",
    "        return A, B\n",
    "\n",
    "ds = PairedMRIDataset(paired_root)\n",
    "dl = DataLoader(ds, batch_size=4, shuffle=False, num_workers=2)\n",
    "print('Dataset size =', len(ds))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Modelo 1: Pix2Pix U-Net (carga checkpoint o warm-start breve)\n",
    "from src.models.pix2pix import UNetGenerator, PatchGANDiscriminator\n",
    "from torch import nn, optim\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "G = UNetGenerator(in_channels=1, out_channels=1).to(device)\n",
    "ckpt_candidates = [Path('outputs/pix2pix/best.pt'), Path('outputs/pix2pix/last.pt')]\n",
    "loaded=False\n",
    "for c in ckpt_candidates:\n",
    "    if c.exists():\n",
    "        try:\n",
    "            G.load_state_dict(torch.load(c, map_location=device))\n",
    "            print('Loaded checkpoint:', c)\n",
    "            loaded=True; break\n",
    "        except Exception as e:\n",
    "            print('Failed to load', c, e)\n",
    "\n",
    "if not loaded:\n",
    "    print('No checkpoint found. Warm-start ~50 steps...')\n",
    "    D = PatchGANDiscriminator(in_channels=2).to(device)\n",
    "    opt_g = optim.Adam(G.parameters(), lr=2e-4, betas=(0.5,0.999))\n",
    "    opt_d = optim.Adam(D.parameters(), lr=2e-4, betas=(0.5,0.999))\n",
    "    L1 = nn.L1Loss(); BCE = nn.BCEWithLogitsLoss()\n",
    "    G.train(); D.train()\n",
    "    steps=0\n",
    "    for A,B in dl:\n",
    "        A,B = A.to(device), B.to(device)\n",
    "        # D\n",
    "        opt_d.zero_grad()\n",
    "        Z = G(A)\n",
    "        pred_real = D(A,B)\n",
    "        pred_fake = D(A,Z.detach())\n",
    "        loss_d = BCE(pred_real, torch.ones_like(pred_real)) + BCE(pred_fake, torch.zeros_like(pred_fake))\n",
    "        loss_d.backward(); opt_d.step()\n",
    "        # G\n",
    "        opt_g.zero_grad()\n",
    "        pred_fake = D(A,Z)\n",
    "        loss_g = BCE(pred_fake, torch.ones_like(pred_fake)) + 100*L1(Z,B)\n",
    "        loss_g.backward(); opt_g.step()\n",
    "        steps += 1\n",
    "        if steps >= 50: break\n",
    "    G.eval()\n",
    "else:\n",
    "    G.eval()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Modelo 2: MONAI 2D UNet (L1) — baseline breve\n",
    "from monai.networks.nets import UNet as MONAI_UNet\n",
    "from torch import nn\n",
    "M = MONAI_UNet(spatial_dims=2, in_channels=1, out_channels=1, channels=(16,32,64,128), strides=(2,2,2), num_res_units=2).to(device)\n",
    "opt_m = torch.optim.Adam(M.parameters(), lr=2e-4)\n",
    "L1 = nn.L1Loss()\n",
    "M.train()\n",
    "steps = 0\n",
    "for A,B in dl:\n",
    "    A,B = A.to(device), B.to(device)\n",
    "    opt_m.zero_grad()\n",
    "    Z = M(A)\n",
    "    loss = L1(Z, B)\n",
    "    loss.backward(); opt_m.step()\n",
    "    steps += 1\n",
    "    if steps >= 100: break\n",
    "M.eval()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluación y tabla de métricas\n",
    "import os\n",
    "import pandas as pd\n",
    "from src.utils.visualization import show_images\n",
    "from torchmetrics.image import StructuralSimilarityIndexMeasure, PeakSignalNoiseRatio\n",
    "\n",
    "os.makedirs('outputs/t1_to_t2', exist_ok=True)\n",
    "\n",
    "def evaluate(forward):\n",
    "    ssim_metric = StructuralSimilarityIndexMeasure(data_range=1.0).to(device)\n",
    "    psnr_metric = PeakSignalNoiseRatio(data_range=1.0).to(device)\n",
    "    ssims, psnrs = [], []\n",
    "    first = True\n",
    "    cache = None\n",
    "    with torch.no_grad():\n",
    "        for i, (A,B) in enumerate(dl):\n",
    "            A,B = A.to(device), B.to(device)\n",
    "            Z = forward(A)\n",
    "            Z01, B01 = (Z+1)/2, (B+1)/2\n",
    "            ssims.append(ssim_metric(Z01, B01).item())\n",
    "            psnrs.append(psnr_metric(Z01, B01).item())\n",
    "            if first:\n",
    "                cache = (A[:4].cpu(), Z[:4].cpu(), B[:4].cpu())\n",
    "                first = False\n",
    "    val_ssim = float(sum(ssims)/len(ssims)) if ssims else 0.0\n",
    "    val_psnr = float(sum(psnrs)/len(psnrs)) if psnrs else 0.0\n",
    "    return val_ssim, val_psnr, cache\n",
    "\n",
    "# Pix2Pix\n",
    "ssim_g, psnr_g, cache_g = evaluate(lambda x: G(x))\n",
    "if cache_g is not None:\n",
    "    a,z,b = cache_g\n",
    "    show_images(torch.cat([a, z, b], dim=0), nrow=4, title='Pix2Pix: A, G(A), B', save_path='outputs/t1_to_t2/grid_pix2pix.png')\n",
    "\n",
    "# MONAI UNet\n",
    "ssim_m, psnr_m, cache_m = evaluate(lambda x: M(x))\n",
    "if cache_m is not None:\n",
    "    a2,z2,b2 = cache_m\n",
    "    show_images(torch.cat([a2, z2, b2], dim=0), nrow=4, title='MONAI UNet: A, M(A), B', save_path='outputs/t1_to_t2/grid_monai_unet.png')\n",
    "\n",
    "# Tabla\n",
    "results = [\n",
    "    {'model': 'Pix2Pix-UNet', 'SSIM': ssim_g, 'PSNR': psnr_g},\n",
    "    {'model': 'MONAI-UNet (L1)', 'SSIM': ssim_m, 'PSNR': psnr_m},\n",
    "]\n",
    "df = pd.DataFrame(results)\n",
    "print(df)\n",
    "df.to_csv('outputs/t1_to_t2/metrics.csv', index=False)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
