{
    "cells":  [
                  {
                      "cell_type":  "markdown",
                      "metadata":  {

                                   },
                      "source":  [
                                     "# 03_pix2pix_mri.ipynb â€” T1â†’T2 synthesis\n\nTraducciÃ³n de T1 a T2 con Pix2Pix (pares alineados). Incluye mÃ©tricas SSIM/PSNR.\n"
                                 ]
                  },
                  {
                      "cell_type":  "code",
                      "execution_count":  null,
                      "metadata":  {

                                   },
                      "outputs":  [

                                  ],
                      "source":  [
                                     "import sys\nif \u0027.\u0027 not in sys.path: sys.path.append(\u0027.\u0027)\nimport torch\nfrom torch import nn, optim\nfrom torch.utils.data import Dataset, DataLoader\nfrom torchvision import transforms\nfrom PIL import Image\nfrom pathlib import Path\nfrom src.models.pix2pix import UNetGenerator, PatchGANDiscriminator\nfrom src.utils.metrics import ssim, psnr\nfrom src.utils.visualization import show_images\n"
                                 ]
                  },
                  {
                      "cell_type":  "code",
                      "execution_count":  null,
                      "metadata":  {

                                   },
                      "outputs":  [

                                  ],
                      "source":  [
                                    "class PairedMRIDataset(Dataset):\n    def __init__(self, root, img_size=256):\n        self.root = Path(root)\n        self.t1 = sorted((self.root/\u0027T1\u0027).glob(\u0027*.png\u0027))\n        self.t2 = sorted((self.root/\u0027T2\u0027).glob(\u0027*.png\u0027))\n        assert len(self.t1) == len(self.t2), \u0027NÃºmero de pares T1/T2 debe coincidir\u0027\n        self.tf = transforms.Compose([transforms.Grayscale(1), transforms.Resize((img_size,img_size)), transforms.ToTensor(), transforms.Normalize([0.5],[0.5])])\n    def __len__(self): return len(self.t1)\n    def __getitem__(self, idx):\n        a = self.tf(Image.open(self.t1[idx]).convert(\u0027L\u0027))\n        b = self.tf(Image.open(self.t2[idx]).convert(\u0027L\u0027))\n        return a, b\n\n# TODO: cambia esta ruta a tu dataset pareado\n# Estructura esperada: dataset_root/ T1/*.png, T2/*.png\nroot = \u0027data/paired_mri\u0027\n# Fallback: intenta generar muestras y usa sample_mri_pairs si paired_mri estÃ¡ vacÃ­o\nfrom pathlib import Path\nimport subprocess, sys\nsample_root = Path(\u0027data/sample_mri_pairs\u0027)\nif not any((Path(root)/\u0027T1\u0027).glob(\u0027*.png\u0027)) or not any((Path(root)/\u0027T2\u0027).glob(\u0027*.png\u0027)):\n    try:\n        subprocess.run([sys.executable, \u0027scripts/make_sample_data.py\u0027], check=False)\n        if any((sample_root/\u0027T1\u0027).glob(\u0027*.png\u0027)) and any((sample_root/\u0027T2\u0027).glob(\u0027*.png\u0027)):\n            root = str(sample_root)\n    except Exception as e:\n        print(\u0027Warning: could not generate sample data:\u0027, e)\nimg_size = 256\nbatch_size = 4\ntrain_ds = PairedMRIDataset(root, img_size=img_size)\ntrain_dl = DataLoader(train_ds, batch_size=batch_size, shuffle=True, num_workers=2)\n\nG = UNetGenerator(in_channels=1, out_channels=1).cuda() if torch.cuda.is_available() else UNetGenerator(1,1)\nD = PatchGANDiscriminator(in_channels=2).cuda() if torch.cuda.is_available() else PatchGANDiscriminator(2)\nopt_g = optim.Adam(G.parameters(), lr=2e-4, betas=(0.5,0.999))\nopt_d = optim.Adam(D.parameters(), lr=2e-4, betas=(0.5,0.999))\nL1 = nn.L1Loss()\nBCE = nn.BCEWithLogitsLoss()\n"
                                 ]
                  },
                  {
                      "cell_type":  "code",
                      "execution_count":  null,
                      "metadata":  {

                                   },
                      "outputs":  [

                                  ],
                      "source":  [
                                     "device = torch.device(\u0027cuda\u0027 if torch.cuda.is_available() else \u0027cpu\u0027)\nG.to(device); D.to(device)\nfor epoch in range(1):\n    for i, (a, b) in enumerate(train_dl):\n        a, b = a.to(device), b.to(device)\n        # ---- D ----\n        opt_d.zero_grad()\n        pred_real = D(a, b)\n        z = G(a)\n        pred_fake = D(a, z.detach())\n        loss_d = BCE(pred_real, torch.ones_like(pred_real)) + BCE(pred_fake, torch.zeros_like(pred_fake))\n        loss_d.backward(); opt_d.step()\n        # ---- G ----\n        opt_g.zero_grad()\n        pred_fake = D(a, z)\n        loss_g = BCE(pred_fake, torch.ones_like(pred_fake)) + 100*L1(z, b)\n        loss_g.backward(); opt_g.step()\n        if i % 50 == 0:\n            with torch.no_grad():\n                s = torch.cat([a[:4], z[:4], b[:4]], dim=0)\n                show_images(s, nrow=4, title=f\u0027Epoch {epoch} iter {i}\u0027)\n            print(\u0027D\u0027, float(loss_d), \u0027G\u0027, float(loss_g), \u0027SSIM\u0027, float(ssim(z, b)), \u0027PSNR\u0027, float(psnr(z, b)))\n"
                                 ]
                  },
                  {
                      "cell_type":  "code",
                      "execution_count":  null,
                      "metadata":  {

                                   },
                      "outputs":  [

                                  ],
                      "source":  [
                                     "from src.utils.visualization import plot_curves, show_images\n",
                                     "from torch.utils.data import random_split\n",
                                     "from torchmetrics.image import StructuralSimilarityIndexMeasure, PeakSignalNoiseRatio\n",
                                     "import os, torch\n",
                                     "device = torch.device(\u0027cuda\u0027 if torch.cuda.is_available() else \u0027cpu\u0027)\n",
                                     "G.eval()\n",
                                     "# build validation split (10%)\n",
                                     "full_ds = PairedMRIDataset(root, img_size=img_size)\n",
                                     "n_val = max(1, int(0.1 * len(full_ds)))\n",
                                     "n_train = len(full_ds) - n_val\n",
                                     "train_subset, val_ds = random_split(full_ds, [n_train, n_val])\n",
                                     "val_dl = DataLoader(val_ds, batch_size=batch_size, shuffle=False, num_workers=2)\n",
                                     "ssim_metric = StructuralSimilarityIndexMeasure(data_range=1.0).to(device)\n",
                                     "psnr_metric = PeakSignalNoiseRatio(data_range=1.0).to(device)\n",
                                     "ssims, psnrs = [], []\n",
                                     "with torch.no_grad():\n",
                                     "    for a,b in val_dl:\n",
                                     "        a,b = a.to(device), b.to(device)\n",
                                     "        z = G(a)\n",
                                     "        z01, b01 = (z+1)/2, (b+1)/2\n",
                                     "        ssims.append(ssim_metric(z01,b01).item())\n",
                                     "        psnrs.append(psnr_metric(z01,b01).item())\n",
                                     "val_ssim = float(sum(ssims)/len(ssims)) if ssims else 0.0\n",
                                     "val_psnr = float(sum(psnrs)/len(psnrs)) if psnrs else 0.0\n",
                                     "print({\u0027val_ssim\u0027: val_ssim, \u0027val_psnr\u0027: val_psnr})\n",
                                     "history = {\u0027val_ssim\u0027:[val_ssim], \u0027val_psnr\u0027:[val_psnr]}\n",
                                     "os.makedirs(\u0027outputs/pix2pix\u0027, exist_ok=True)\n",
                                     "plot_curves(history, title=\u0027Pix2Pix validation\u0027, save_path=\u0027outputs/pix2pix/metrics.png\u0027)\n",
                                     "samp_a, samp_b = next(iter(val_dl)) if len(val_dl)\u003e0 else (a.cpu()[:4], b.cpu()[:4])\n",
                                     "samp_a = samp_a.to(device)\n",
                                     "samp_z = G(samp_a).cpu()\n",
                                     "show_images(torch.cat([samp_a.cpu()[:4], samp_z[:4], samp_b[:4]], dim=0), nrow=4, title=\u0027Val: A, G(A), B\u0027, save_path=\u0027outputs/pix2pix/val_grid.png\u0027)\n"
                                 ]
                  }
              ],
    "metadata":  {
                     "kernelspec":  {
                                        "display_name":  "Python 3",
                                        "language":  "python",
                                        "name":  "python3"
                                    },
                     "language_info":  {
                                           "name":  "python",
                                           "version":  "3.10"
                                       }
                 },
    "nbformat":  4,
    "nbformat_minor":  5
}
